{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necesarios\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0X</th>\n",
       "      <th>0Y</th>\n",
       "      <th>1X</th>\n",
       "      <th>1Y</th>\n",
       "      <th>2X</th>\n",
       "      <th>2Y</th>\n",
       "      <th>3X</th>\n",
       "      <th>3Y</th>\n",
       "      <th>4X</th>\n",
       "      <th>4Y</th>\n",
       "      <th>...</th>\n",
       "      <th>59_TO_00</th>\n",
       "      <th>60_TO_00</th>\n",
       "      <th>61_TO_00</th>\n",
       "      <th>62_TO_00</th>\n",
       "      <th>63_TO_00</th>\n",
       "      <th>64_TO_00</th>\n",
       "      <th>65_TO_00</th>\n",
       "      <th>66_TO_00</th>\n",
       "      <th>67_TO_00</th>\n",
       "      <th>Etiqueta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-133</td>\n",
       "      <td>-28</td>\n",
       "      <td>-127</td>\n",
       "      <td>2</td>\n",
       "      <td>-119</td>\n",
       "      <td>32</td>\n",
       "      <td>-111</td>\n",
       "      <td>61</td>\n",
       "      <td>-102</td>\n",
       "      <td>92</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044098</td>\n",
       "      <td>0.040615</td>\n",
       "      <td>0.033386</td>\n",
       "      <td>0.033141</td>\n",
       "      <td>0.032766</td>\n",
       "      <td>0.038585</td>\n",
       "      <td>0.033659</td>\n",
       "      <td>0.034049</td>\n",
       "      <td>0.034275</td>\n",
       "      <td>alex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-132</td>\n",
       "      <td>-32</td>\n",
       "      <td>-126</td>\n",
       "      <td>-1</td>\n",
       "      <td>-119</td>\n",
       "      <td>30</td>\n",
       "      <td>-111</td>\n",
       "      <td>60</td>\n",
       "      <td>-101</td>\n",
       "      <td>90</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043361</td>\n",
       "      <td>0.040404</td>\n",
       "      <td>0.033296</td>\n",
       "      <td>0.032684</td>\n",
       "      <td>0.032851</td>\n",
       "      <td>0.038371</td>\n",
       "      <td>0.033296</td>\n",
       "      <td>0.033592</td>\n",
       "      <td>0.033742</td>\n",
       "      <td>alex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-133</td>\n",
       "      <td>-32</td>\n",
       "      <td>-128</td>\n",
       "      <td>-1</td>\n",
       "      <td>-121</td>\n",
       "      <td>30</td>\n",
       "      <td>-112</td>\n",
       "      <td>59</td>\n",
       "      <td>-102</td>\n",
       "      <td>90</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043361</td>\n",
       "      <td>0.040001</td>\n",
       "      <td>0.032851</td>\n",
       "      <td>0.032684</td>\n",
       "      <td>0.032405</td>\n",
       "      <td>0.038371</td>\n",
       "      <td>0.033296</td>\n",
       "      <td>0.033592</td>\n",
       "      <td>0.033742</td>\n",
       "      <td>alex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-134</td>\n",
       "      <td>-33</td>\n",
       "      <td>-129</td>\n",
       "      <td>-2</td>\n",
       "      <td>-122</td>\n",
       "      <td>28</td>\n",
       "      <td>-113</td>\n",
       "      <td>59</td>\n",
       "      <td>-103</td>\n",
       "      <td>90</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043515</td>\n",
       "      <td>0.040615</td>\n",
       "      <td>0.033296</td>\n",
       "      <td>0.032684</td>\n",
       "      <td>0.032405</td>\n",
       "      <td>0.038780</td>\n",
       "      <td>0.033296</td>\n",
       "      <td>0.033592</td>\n",
       "      <td>0.034275</td>\n",
       "      <td>alex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-134</td>\n",
       "      <td>-32</td>\n",
       "      <td>-128</td>\n",
       "      <td>-1</td>\n",
       "      <td>-121</td>\n",
       "      <td>30</td>\n",
       "      <td>-112</td>\n",
       "      <td>60</td>\n",
       "      <td>-102</td>\n",
       "      <td>91</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043941</td>\n",
       "      <td>0.040615</td>\n",
       "      <td>0.033296</td>\n",
       "      <td>0.032684</td>\n",
       "      <td>0.032851</td>\n",
       "      <td>0.038780</td>\n",
       "      <td>0.033742</td>\n",
       "      <td>0.034046</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>alex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>-200</td>\n",
       "      <td>-70</td>\n",
       "      <td>-196</td>\n",
       "      <td>-16</td>\n",
       "      <td>-188</td>\n",
       "      <td>38</td>\n",
       "      <td>-180</td>\n",
       "      <td>92</td>\n",
       "      <td>-165</td>\n",
       "      <td>147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109602</td>\n",
       "      <td>0.102319</td>\n",
       "      <td>0.086870</td>\n",
       "      <td>0.086501</td>\n",
       "      <td>0.086669</td>\n",
       "      <td>0.101265</td>\n",
       "      <td>0.088007</td>\n",
       "      <td>0.087862</td>\n",
       "      <td>0.089561</td>\n",
       "      <td>villasante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>-197</td>\n",
       "      <td>-65</td>\n",
       "      <td>-196</td>\n",
       "      <td>-14</td>\n",
       "      <td>-189</td>\n",
       "      <td>40</td>\n",
       "      <td>-180</td>\n",
       "      <td>94</td>\n",
       "      <td>-166</td>\n",
       "      <td>149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107240</td>\n",
       "      <td>0.102013</td>\n",
       "      <td>0.087542</td>\n",
       "      <td>0.086501</td>\n",
       "      <td>0.086133</td>\n",
       "      <td>0.100086</td>\n",
       "      <td>0.086937</td>\n",
       "      <td>0.087200</td>\n",
       "      <td>0.088215</td>\n",
       "      <td>villasante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>-192</td>\n",
       "      <td>-55</td>\n",
       "      <td>-191</td>\n",
       "      <td>-1</td>\n",
       "      <td>-183</td>\n",
       "      <td>53</td>\n",
       "      <td>-174</td>\n",
       "      <td>108</td>\n",
       "      <td>-160</td>\n",
       "      <td>161</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111209</td>\n",
       "      <td>0.103915</td>\n",
       "      <td>0.089948</td>\n",
       "      <td>0.089265</td>\n",
       "      <td>0.089218</td>\n",
       "      <td>0.104645</td>\n",
       "      <td>0.092025</td>\n",
       "      <td>0.091334</td>\n",
       "      <td>0.091974</td>\n",
       "      <td>villasante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>-197</td>\n",
       "      <td>-62</td>\n",
       "      <td>-193</td>\n",
       "      <td>-8</td>\n",
       "      <td>-186</td>\n",
       "      <td>46</td>\n",
       "      <td>-177</td>\n",
       "      <td>100</td>\n",
       "      <td>-164</td>\n",
       "      <td>154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111398</td>\n",
       "      <td>0.104198</td>\n",
       "      <td>0.091299</td>\n",
       "      <td>0.090626</td>\n",
       "      <td>0.091075</td>\n",
       "      <td>0.104897</td>\n",
       "      <td>0.091215</td>\n",
       "      <td>0.090654</td>\n",
       "      <td>0.091974</td>\n",
       "      <td>villasante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>-198</td>\n",
       "      <td>-42</td>\n",
       "      <td>-193</td>\n",
       "      <td>11</td>\n",
       "      <td>-183</td>\n",
       "      <td>64</td>\n",
       "      <td>-174</td>\n",
       "      <td>116</td>\n",
       "      <td>-160</td>\n",
       "      <td>169</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117112</td>\n",
       "      <td>0.109444</td>\n",
       "      <td>0.094677</td>\n",
       "      <td>0.093348</td>\n",
       "      <td>0.092276</td>\n",
       "      <td>0.107274</td>\n",
       "      <td>0.095881</td>\n",
       "      <td>0.096128</td>\n",
       "      <td>0.096551</td>\n",
       "      <td>villasante</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1456 rows × 205 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0X  0Y   1X  1Y   2X  2Y   3X   3Y   4X   4Y  ...  59_TO_00  60_TO_00  \\\n",
       "0   -133 -28 -127   2 -119  32 -111   61 -102   92  ...  0.044098  0.040615   \n",
       "1   -132 -32 -126  -1 -119  30 -111   60 -101   90  ...  0.043361  0.040404   \n",
       "2   -133 -32 -128  -1 -121  30 -112   59 -102   90  ...  0.043361  0.040001   \n",
       "3   -134 -33 -129  -2 -122  28 -113   59 -103   90  ...  0.043515  0.040615   \n",
       "4   -134 -32 -128  -1 -121  30 -112   60 -102   91  ...  0.043941  0.040615   \n",
       "..   ...  ..  ...  ..  ...  ..  ...  ...  ...  ...  ...       ...       ...   \n",
       "207 -200 -70 -196 -16 -188  38 -180   92 -165  147  ...  0.109602  0.102319   \n",
       "208 -197 -65 -196 -14 -189  40 -180   94 -166  149  ...  0.107240  0.102013   \n",
       "209 -192 -55 -191  -1 -183  53 -174  108 -160  161  ...  0.111209  0.103915   \n",
       "210 -197 -62 -193  -8 -186  46 -177  100 -164  154  ...  0.111398  0.104198   \n",
       "211 -198 -42 -193  11 -183  64 -174  116 -160  169  ...  0.117112  0.109444   \n",
       "\n",
       "     61_TO_00  62_TO_00  63_TO_00  64_TO_00  65_TO_00  66_TO_00  67_TO_00  \\\n",
       "0    0.033386  0.033141  0.032766  0.038585  0.033659  0.034049  0.034275   \n",
       "1    0.033296  0.032684  0.032851  0.038371  0.033296  0.033592  0.033742   \n",
       "2    0.032851  0.032684  0.032405  0.038371  0.033296  0.033592  0.033742   \n",
       "3    0.033296  0.032684  0.032405  0.038780  0.033296  0.033592  0.034275   \n",
       "4    0.033296  0.032684  0.032851  0.038780  0.033742  0.034046  0.034188   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "207  0.086870  0.086501  0.086669  0.101265  0.088007  0.087862  0.089561   \n",
       "208  0.087542  0.086501  0.086133  0.100086  0.086937  0.087200  0.088215   \n",
       "209  0.089948  0.089265  0.089218  0.104645  0.092025  0.091334  0.091974   \n",
       "210  0.091299  0.090626  0.091075  0.104897  0.091215  0.090654  0.091974   \n",
       "211  0.094677  0.093348  0.092276  0.107274  0.095881  0.096128  0.096551   \n",
       "\n",
       "       Etiqueta  \n",
       "0          alex  \n",
       "1          alex  \n",
       "2          alex  \n",
       "3          alex  \n",
       "4          alex  \n",
       "..          ...  \n",
       "207  villasante  \n",
       "208  villasante  \n",
       "209  villasante  \n",
       "210  villasante  \n",
       "211  villasante  \n",
       "\n",
       "[1456 rows x 205 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar CSVs\n",
    "\n",
    "alex = pd.read_csv('data/train_data/csv/alex.csv',sep=',',on_bad_lines='skip', encoding='latin-1', index_col=0)\n",
    "endika = pd.read_csv('data/train_data/csv/endika.csv',sep=',',on_bad_lines='skip', encoding='latin-1', index_col=0)\n",
    "gorka = pd.read_csv('data/train_data/csv/gorka.csv',sep=',',on_bad_lines='skip', encoding='latin-1', index_col=0)\n",
    "junkus = pd.read_csv('data/train_data/csv/junkus.csv',sep=',',on_bad_lines='skip', encoding='latin-1', index_col=0)\n",
    "luis = pd.read_csv('data/train_data/csv/luis.csv',sep=',',on_bad_lines='skip', encoding='latin-1', index_col=0)\n",
    "victor = pd.read_csv('data/train_data/csv/victor.csv',sep=',',on_bad_lines='skip', encoding='latin-1', index_col=0)\n",
    "villasante = pd.read_csv('data/train_data/csv/villasante.csv',sep=',',on_bad_lines='skip', encoding='latin-1', index_col=0)\n",
    "\n",
    "\n",
    "endika_test = pd.read_csv('data/train_data/csv/endika_test.csv',sep=',',on_bad_lines='skip', encoding='latin-1', index_col=0)\n",
    "\n",
    "todos = pd.concat([alex,endika,gorka,junkus,luis,victor,villasante],axis=0)\n",
    "todos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "etiquetas = ['0X','0Y','1X','1Y','2X','2Y','3X','3Y','4X','4Y','5X','5Y','6X','6Y','7X','7Y','8X','8Y','9X','9Y','10X','10Y','11X','11Y','12X','12Y','13X','13Y','14X','14Y','15X','15Y','16X','16Y','17X','17Y','18X','18Y','19X','19Y','20X','20Y','21X','21Y','22X','22Y','23X','23Y','24X','24Y','25X','25Y','26X','26Y','27X','27Y','28X','28Y','29X','29Y','30X','30Y','31X','31Y','32X','32Y','33X','33Y','34X','34Y','35X','35Y','36X','36Y','37X','37Y','38X','38Y','39X','39Y','40X','40Y','41X','41Y','42X','42Y','43X','43Y','44X','44Y','45X','45Y','46X','46Y','47X','47Y','48X','48Y','49X','49Y','50X','50Y','51X','51Y','52X','52Y','53X','53Y','54X','54Y','55X','55Y','56X','56Y','57X','57Y','58X','58Y','59X','59Y','60X','60Y','61X','61Y','62X','62Y','63X','63Y','64X','64Y','65X','65Y','66X','66Y','67X','67Y','0_TO_00','1_TO_00','2_TO_00','3_TO_00','4_TO_00','5_TO_00','6_TO_00','7_TO_00','8_TO_00','9_TO_00','10_TO_00','11_TO_00','12_TO_00','13_TO_00','14_TO_00','15_TO_00','16_TO_00','17_TO_00','18_TO_00','19_TO_00','20_TO_00','21_TO_00','22_TO_00','23_TO_00','24_TO_00','25_TO_00','26_TO_00','27_TO_00','28_TO_00','29_TO_00','30_TO_00','31_TO_00','32_TO_00','33_TO_00','34_TO_00','35_TO_00','36_TO_00','37_TO_00','38_TO_00','39_TO_00','40_TO_00','41_TO_00','42_TO_00','43_TO_00','44_TO_00','45_TO_00','46_TO_00','47_TO_00','48_TO_00','49_TO_00','50_TO_00','51_TO_00','52_TO_00','53_TO_00','54_TO_00','55_TO_00','56_TO_00','57_TO_00','58_TO_00','59_TO_00','60_TO_00','61_TO_00','62_TO_00','63_TO_00','64_TO_00','65_TO_00','66_TO_00','67_TO_00','Etiqueta']\n",
    "\n",
    "etiquetas_coordenadas = ['0X','0Y','1X','1Y','2X','2Y','3X','3Y','4X','4Y','5X','5Y','6X','6Y','7X','7Y','8X','8Y','9X','9Y','10X','10Y','11X','11Y','12X','12Y','13X','13Y','14X','14Y','15X','15Y','16X','16Y','17X','17Y','18X','18Y','19X','19Y','20X','20Y','21X','21Y','22X','22Y','23X','23Y','24X','24Y','25X','25Y','26X','26Y','27X','27Y','28X','28Y','29X','29Y','30X','30Y','31X','31Y','32X','32Y','33X','33Y','34X','34Y','35X','35Y','36X','36Y','37X','37Y','38X','38Y','39X','39Y','40X','40Y','41X','41Y','42X','42Y','43X','43Y','44X','44Y','45X','45Y','46X','46Y','47X','47Y','48X','48Y','49X','49Y','50X','50Y','51X','51Y','52X','52Y','53X','53Y','54X','54Y','55X','55Y','56X','56Y','57X','57Y','58X','58Y','59X','59Y','60X','60Y','61X','61Y','62X','62Y','63X','63Y','64X','64Y','65X','65Y','66X','66Y','67X','67Y']\n",
    "\n",
    "etiquetas_distancias = ['0_TO_00','1_TO_00','2_TO_00','3_TO_00','4_TO_00','5_TO_00','6_TO_00','7_TO_00','8_TO_00','9_TO_00','10_TO_00','11_TO_00','12_TO_00','13_TO_00','14_TO_00','15_TO_00','16_TO_00','17_TO_00','18_TO_00','19_TO_00','20_TO_00','21_TO_00','22_TO_00','23_TO_00','24_TO_00','25_TO_00','26_TO_00','27_TO_00','28_TO_00','29_TO_00','30_TO_00','31_TO_00','32_TO_00','33_TO_00','34_TO_00','35_TO_00','36_TO_00','37_TO_00','38_TO_00','39_TO_00','40_TO_00','41_TO_00','42_TO_00','43_TO_00','44_TO_00','45_TO_00','46_TO_00','47_TO_00','48_TO_00','49_TO_00','50_TO_00','51_TO_00','52_TO_00','53_TO_00','54_TO_00','55_TO_00','56_TO_00','57_TO_00','58_TO_00','59_TO_00','60_TO_00','61_TO_00','62_TO_00','63_TO_00','64_TO_00','65_TO_00','66_TO_00','67_TO_00']\n",
    "\n",
    "personas = todos['Etiqueta'].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coordenadas faciales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eiros/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/eiros/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo multinomial es: 0.6225490196078431\n",
      "Precisión del modelo ovr es: 0.7156862745098039\n"
     ]
    }
   ],
   "source": [
    "x_train = todos[etiquetas_coordenadas]\n",
    "y_train = todos['Etiqueta']\n",
    "\n",
    "x_test = endika_test[etiquetas_coordenadas]\n",
    "y_test = endika_test['Etiqueta']\n",
    "\n",
    "logistic_classifier = LogisticRegression(multi_class='multinomial').fit(x_train, y_train)\n",
    "y_pred = logistic_classifier.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Precisión del modelo multinomial es: {accuracy}')\n",
    "\n",
    "\n",
    "logistic_classifier = LogisticRegression(multi_class='ovr').fit(x_train, y_train)\n",
    "y_pred = logistic_classifier.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Precisión del modelo ovr es: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearst Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo con n_neighbors=1: 0.5294117647058824\n",
      "Precisión del modelo con n_neighbors=2: 0.5049019607843137\n",
      "Precisión del modelo con n_neighbors=3: 0.4362745098039216\n",
      "Precisión del modelo con n_neighbors=4: 0.45588235294117646\n",
      "Precisión del modelo con n_neighbors=5: 0.43137254901960786\n",
      "Precisión del modelo con n_neighbors=6: 0.4019607843137255\n",
      "Precisión del modelo con n_neighbors=7: 0.4117647058823529\n",
      "Precisión del modelo con n_neighbors=8: 0.4019607843137255\n",
      "Precisión del modelo con n_neighbors=9: 0.4019607843137255\n",
      "Precisión del modelo con n_neighbors=12: 0.4068627450980392\n",
      "Precisión del modelo con n_neighbors=13: 0.4019607843137255\n",
      "Precisión del modelo con n_neighbors=14: 0.4068627450980392\n",
      "Precisión del modelo con n_neighbors=15: 0.4068627450980392\n",
      "Precisión del modelo con n_neighbors=16: 0.4019607843137255\n"
     ]
    }
   ],
   "source": [
    "x_train = todos[etiquetas_coordenadas]\n",
    "y_train = todos['Etiqueta']\n",
    "\n",
    "x_test = endika_test[etiquetas_coordenadas]\n",
    "y_test = endika_test['Etiqueta']\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "for i in range(1,51,1):\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=i)\n",
    "\n",
    "    knn_classifier.fit(x_train, y_train)\n",
    "\n",
    "    y_pred = knn_classifier.predict(x_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    if accuracy > 0.4:\n",
    "        print(f'Precisión del modelo con n_neighbors={i}: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distancias faciales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo multinomial es: 1.0\n",
      "Precisión del modelo ovr es: 1.0\n"
     ]
    }
   ],
   "source": [
    "x_train = todos[etiquetas_distancias]\n",
    "y_train = todos['Etiqueta']\n",
    "\n",
    "x_test = endika_test[etiquetas_distancias]\n",
    "y_test = endika_test['Etiqueta']\n",
    "\n",
    "logistic_classifier = LogisticRegression(multi_class='multinomial').fit(x_train, y_train)\n",
    "y_pred = logistic_classifier.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Precisión del modelo multinomial es: {accuracy}')\n",
    "\n",
    "\n",
    "logistic_classifier = LogisticRegression(multi_class='ovr').fit(x_train, y_train)\n",
    "y_pred = logistic_classifier.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Precisión del modelo ovr es: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearst Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo con n_neighbors=1: 1.0\n",
      "Precisión del modelo con n_neighbors=3: 1.0\n",
      "Precisión del modelo con n_neighbors=5: 1.0\n",
      "Precisión del modelo con n_neighbors=7: 1.0\n",
      "Precisión del modelo con n_neighbors=9: 1.0\n",
      "Precisión del modelo con n_neighbors=11: 1.0\n",
      "Precisión del modelo con n_neighbors=13: 1.0\n",
      "Precisión del modelo con n_neighbors=15: 1.0\n",
      "Precisión del modelo con n_neighbors=17: 1.0\n",
      "Precisión del modelo con n_neighbors=19: 1.0\n",
      "Precisión del modelo con n_neighbors=21: 1.0\n",
      "Precisión del modelo con n_neighbors=23: 1.0\n",
      "Precisión del modelo con n_neighbors=25: 1.0\n",
      "Precisión del modelo con n_neighbors=27: 1.0\n",
      "Precisión del modelo con n_neighbors=29: 1.0\n",
      "Precisión del modelo con n_neighbors=31: 1.0\n",
      "Precisión del modelo con n_neighbors=33: 1.0\n",
      "Precisión del modelo con n_neighbors=35: 1.0\n",
      "Precisión del modelo con n_neighbors=37: 1.0\n",
      "Precisión del modelo con n_neighbors=39: 1.0\n",
      "Precisión del modelo con n_neighbors=41: 1.0\n",
      "Precisión del modelo con n_neighbors=43: 1.0\n",
      "Precisión del modelo con n_neighbors=45: 1.0\n",
      "Precisión del modelo con n_neighbors=47: 1.0\n",
      "Precisión del modelo con n_neighbors=49: 1.0\n",
      "Precisión del modelo con n_neighbors=51: 1.0\n",
      "Precisión del modelo con n_neighbors=53: 1.0\n",
      "Precisión del modelo con n_neighbors=55: 1.0\n",
      "Precisión del modelo con n_neighbors=57: 1.0\n",
      "Precisión del modelo con n_neighbors=59: 1.0\n",
      "Precisión del modelo con n_neighbors=61: 1.0\n",
      "Precisión del modelo con n_neighbors=63: 1.0\n",
      "Precisión del modelo con n_neighbors=65: 1.0\n",
      "Precisión del modelo con n_neighbors=67: 1.0\n",
      "Precisión del modelo con n_neighbors=69: 1.0\n",
      "Precisión del modelo con n_neighbors=71: 1.0\n",
      "Precisión del modelo con n_neighbors=73: 1.0\n",
      "Precisión del modelo con n_neighbors=75: 1.0\n",
      "Precisión del modelo con n_neighbors=77: 1.0\n",
      "Precisión del modelo con n_neighbors=79: 1.0\n",
      "Precisión del modelo con n_neighbors=81: 1.0\n",
      "Precisión del modelo con n_neighbors=83: 1.0\n",
      "Precisión del modelo con n_neighbors=85: 1.0\n",
      "Precisión del modelo con n_neighbors=87: 1.0\n",
      "Precisión del modelo con n_neighbors=89: 1.0\n",
      "Precisión del modelo con n_neighbors=91: 1.0\n",
      "Precisión del modelo con n_neighbors=93: 1.0\n",
      "Precisión del modelo con n_neighbors=95: 1.0\n",
      "Precisión del modelo con n_neighbors=97: 1.0\n",
      "Precisión del modelo con n_neighbors=99: 1.0\n"
     ]
    }
   ],
   "source": [
    "x_train = todos[etiquetas_distancias]\n",
    "y_train = todos['Etiqueta']\n",
    "\n",
    "x_test = endika_test[etiquetas_distancias]\n",
    "y_test = endika_test['Etiqueta']\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "for i in range(1,101,2):\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=i)\n",
    "\n",
    "    knn_classifier.fit(x_train, y_train)\n",
    "\n",
    "    y_pred = knn_classifier.predict(x_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    if accuracy > 0.1:\n",
    "        print(f'Precisión del modelo con n_neighbors={i}: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coordenadas faciales + Distancias faciales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearst Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegresion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
