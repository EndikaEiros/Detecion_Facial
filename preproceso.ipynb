{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7lQczqK5Y5n"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import os\n",
        "import cv2\n",
        "import dlib\n",
        "import imutils\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from time import sleep\n",
        "from math import sqrt\n",
        "from tqdm import tqdm\n",
        "from imutils import face_utils\n",
        "from sklearn.metrics import *\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A lo largo de este notebook, se visualizan alguna de las pruebas realizadas para el desarrollo del sistema de identificación de rostros.\n",
        "\n",
        "En este caso, se ven los resultados obtenidos utilizando a 2 personas para el entrenamiento.\n",
        "\n",
        "Se probarán los siguientes clasificadores:\n",
        "- Logistic Regression\n",
        "- Multi-Layer Perceptron\n",
        "- K Nearest Neighbors"
      ],
      "metadata": {
        "id": "TU6lLqsNaesL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En primer lugar, sacaremos toda la información relevante de cada uno de los rostros utilizando técnicas de Visión por Computador. Esto no permitirá generar un dataset con el que realizaremos las pruebas.\n",
        "\n",
        "En la siguiente imagen podemos observar los 68 puntos que se pueden sacar de una imagen y, por lo tanto, las 2278 distancias posibles entre todos estos puntos."
      ],
      "metadata": {
        "id": "9kQe0r8ha15E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keanu = cv2.imread('data/keanu_grande.jpg')\n",
        "\n",
        "p = \"models/shape_predictor_68_face_landmarks.dat\"\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "predictor = dlib.shape_predictor(p)\n",
        "\n",
        "# Almacenar caras\n",
        "data = []\n",
        "\n",
        "# Preprocesar frame y obtener caras detectadas\n",
        "# frame = imutils.resize(keanu, width=640)\n",
        "\n",
        "gray = cv2.cvtColor(keanu, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "rects = detector(gray, 0)\n",
        "\n",
        "for (i, rect) in enumerate(rects):\n",
        "\n",
        "    shape = predictor(gray, rect)\n",
        "    shape = face_utils.shape_to_np(shape)\n",
        "\n",
        "    for i in range(0,68):\n",
        "        for j in range(i+1,68):\n",
        "\n",
        "            # frame = cv2.line(frame,[, ],[],color=(255,0,0), thickness=1)\n",
        "            start_point = (int(shape[i][0]), int(shape[i][1]))\n",
        "\n",
        "            end_point = (int(shape[j][0]),int(shape[j][1]))\n",
        "\n",
        "            color = (0, 255, 0)\n",
        "            keanu = cv2.line(keanu, start_point, end_point, color, 1)\n",
        "\n",
        "cv2_imshow(keanu)\n",
        "#cv2.imwrite('keanu_todos.jpg', keanu)"
      ],
      "metadata": {
        "id": "uuP1rXwcaH4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cargamos los datos previamente introducidos en un csv en un DataFrame"
      ],
      "metadata": {
        "id": "PskCd-l5NBd-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5RyMrY1SM3Nn"
      },
      "outputs": [],
      "source": [
        "# Crear cabeceras del Dataframe\n",
        "headers = []\n",
        "for i in range(0,68):\n",
        "    for j in range(i+1,68):\n",
        "        headers.append(f'{i}TO{j}')\n",
        "# print(headers)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar train\n",
        "landmarks_train_df = pd.read_csv(\"path/to/train/csv\", columns=headers)\n",
        "\n",
        "X_train = landmarks_train_df.drop(['Etiqueta'], axis=1)\n",
        "y_train = landmarks_train_df['Etiqueta']"
      ],
      "metadata": {
        "id": "SOkfpIpENGWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar test\n",
        "landmarks_test_df = pd.read_csv(\"path/to/test/csv\", columns=headers)\n",
        "\n",
        "X_test = landmarks_train_df.drop(['Etiqueta'], axis=1)\n",
        "y_test = landmarks_train_df['Etiqueta']"
      ],
      "metadata": {
        "id": "uIWm5WBYN04q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PRUEBA 1: UTILIZANDO TODAS LAS DISTANCIAS"
      ],
      "metadata": {
        "id": "eVKeGiz2O-S8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para esta primera prueba utilizaremos todos los datos posibles para hacer la clasificación con intención de obtener unas métricas base."
      ],
      "metadata": {
        "id": "dvzt-RthQAHB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "olcgXu-77QfS",
        "outputId": "e76ab92d-87ef-4271-db2c-e66a20dbb210"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-8cfb02fc6243>\"\u001b[0;36m, line \u001b[0;32m14\u001b[0m\n\u001b[0;31m    +\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expression cannot contain assignment, perhaps you meant \"==\"?\n"
          ]
        }
      ],
      "source": [
        "###### Regresión Logística ######\n",
        "\n",
        "rl_model = LogisticRegression(max_iter=10000)\n",
        "rl_model.fit(X_train, y_train)\n",
        "best_value_lr = rl_model.score(X_test, y_test)\n",
        "\n",
        "\n",
        "#### Multi-layer Perceptron #####\n",
        "\n",
        "mlp_model = MLPClassifier(\n",
        "    hidden_layer_sizes=[20, 40],\n",
        "    activation='relu',\n",
        "    early_stopping=True,\n",
        "    random_state=13,\n",
        "    max_iter=10000,\n",
        "    solver='adam',\n",
        "    verbose=False\n",
        ")\n",
        "mlp_model.fit(X_train, y_train)\n",
        "best_value_mlp = mlp_model.score(X_test, y_test)\n",
        "\n",
        "\n",
        "###### K Nearst Neighbors #######\n",
        "\n",
        "vecinos =  []\n",
        "for k in range(1, 101):\n",
        "    model = KNeighborsClassifier(k)\n",
        "    model.fit(X_train, y_train)\n",
        "    vecinos.append((k, model.score(X_test, y_test)))\n",
        "\n",
        "# Accuracy máximo obtenido\n",
        "best_value_knn = max(vecinos, key=lambda x:x[1])[1]\n",
        "\n",
        "########## Resultados ###########\n",
        "\n",
        "print(f\"K Nearst Neighbors - accuracy: {best_value_knn}\")\n",
        "print(f\"Logistic Regression - accuracy: {best_value_lr}\")\n",
        "print(f\"Multi-layer Perceptron - accuracy: {best_value_mlp}\")\n",
        "\n",
        "# Optimización de K\n",
        "\n",
        "print('\\nK optimization')\n",
        "plt.scatter(*zip(*[i for i in vecinos if vecinos.index(i) % 2 == 0]))\n",
        "plt.axis((0, 100, 0.5, 1))\n",
        "plt.xlabel('Valor de k', fontsize=15)\n",
        "plt.ylabel('Accuracy', fontsize=15)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A pesar de que se obtienen muy buenos resultados, realizar el cálculo de todas las distancias por cada rostro y cada frame resulta muy costoso. Además, el algoritmo k-NN tiene un coste adicional, ya que para hacer cada predicción tiene que calcular todas las distancias entre los registros para buscar los k más cercanos. Por lo que será necesario hacer una reducción de atributos para que el funcionamiento del sistema sea viable."
      ],
      "metadata": {
        "id": "YVcyIdsxPSKx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PRUEBA 2: SELECCIONANDO MANUALMENTE ALGUNAS DISTANCIAS"
      ],
      "metadata": {
        "id": "ch-Us250Pyxh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para comprobar si es viable realizar el cálculo de menos distancias para la identificación en tiempo real, realizaremos otra prueba escogiendo manualmente las imágenes del rostro que se observan en la siguiente imagen:"
      ],
      "metadata": {
        "id": "R6Zii6ifQ11p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imagen = cv2.imread('data/keanu_grande.jpg')\n",
        "\n",
        "# Cargar el detector de rostros de DLIB\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "predictor = dlib.shape_predictor(\"/content/sample_data/shape_predictor_68_face_landmarks.dat\")\n",
        "\n",
        "# Detectar rostros en la imagen\n",
        "imagen_rgb = cv2.cvtColor(imagen, cv2.COLOR_BGR2RGB)\n",
        "rostros = detector(imagen_rgb)\n",
        "\n",
        "init = [1, 36, 42, 27, 31, 17, 22, 48, 6, 8, 51]\n",
        "fin = [15, 39, 45, 33, 35, 21, 26, 54, 10, 57, 33]\n",
        "\n",
        "for rostro in rostros:\n",
        "    landmarks = predictor(imagen_rgb, rostro)\n",
        "\n",
        "    for p1, p2 in zip(init, fin):\n",
        "        cv2.line(imagen, (landmarks.part(p1).x, landmarks.part(p1).y), (landmarks.part(p2).x, landmarks.part(p2).y), (0, 255, 255), 2)\n",
        "        cv2.circle(imagen, (landmarks.part(p1).x, landmarks.part(p1).y), 2, (0, 0, 255), -1)\n",
        "        cv2.circle(imagen, (landmarks.part(p2).x, landmarks.part(p2).y), 2, (0, 0, 255), -1)\n",
        "\n",
        "cv2_imshow(imagen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "V9WjUTCjRPQx",
        "outputId": "78ccf114-266c-459a-de56-041483fa34ae"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-8ca603fdbc5b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimagen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/keanu_grande.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Cargar el detector de rostros de DLIB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdetector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frontal_face_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_predictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/sample_data/shape_predictor_68_face_landmarks.dat\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener columnas deseadas\n",
        "init = [1, 36, 42, 27, 31, 17, 22, 48, 6, 8, 51]\n",
        "fin = [15, 39, 45, 33, 35, 21, 26, 54, 10, 57, 33]\n",
        "new_colums = list()\n",
        "for p1, p2 in zip(init, fin):\n",
        "    new_colums.append(f'{p1}TO{p2}')\n",
        "\n",
        "# Cargar nuevo train y test\n",
        "\n",
        "#TODO COGER SOLO LAS NEW COLUMNS\n",
        "X_train_prueba2 = landmarks_train_df.drop(['Etiqueta'], axis=1)\n",
        "y_train_prueba2 = landmarks_train_df['Etiqueta']\n",
        "\n",
        "X_test_prueba2 = landmarks_train_df.drop(['Etiqueta'], axis=1)\n",
        "y_test_prueba2 = landmarks_train_df['Etiqueta']"
      ],
      "metadata": {
        "id": "82hafVYKSXjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###### Regresión Logística ######\n",
        "\n",
        "rl_model = LogisticRegression(max_iter=10000)\n",
        "rl_model.fit(X_train_prueba2, y_train_prueba2)\n",
        "best_value_lr = rl_model.score(X_test_prueba2, y_test_prueba2)\n",
        "\n",
        "\n",
        "#### Multi-layer Perceptron #####\n",
        "\n",
        "mlp_model = MLPClassifier(\n",
        "    hidden_layer_sizes=[20, 40],\n",
        "    activation='relu',\n",
        "    early_stopping=True,\n",
        "    +\n",
        "    random_state=13,\n",
        "    max_iter=10000,\n",
        "    solver='adam',\n",
        "    verbose=False\n",
        ")\n",
        "mlp_model.fit(X_train_prueba2, y_train_prueba2)\n",
        "best_value_mlp = mlp_model.score(X_test_prueba2, y_test_prueba2)\n",
        "\n",
        "\n",
        "###### K Nearst Neighbors #######\n",
        "\n",
        "vecinos =  []\n",
        "for k in range(1, 101):\n",
        "    model = KNeighborsClassifier(k)\n",
        "    model.fit(X_train_prueba2, y_train_prueba2)\n",
        "    vecinos.append((k, model.score(X_test_prueba2, y_test_prueba2)))\n",
        "\n",
        "# Accuracy máximo obtenido\n",
        "best_value_knn = max(vecinos, key=lambda x:x[1])[1]\n",
        "\n",
        "########## Resultados ###########\n",
        "\n",
        "print(f\"K Nearst Neighbors - accuracy: {best_value_knn}\")\n",
        "print(f\"Logistic Regression - accuracy: {best_value_lr}\")\n",
        "print(f\"Multi-layer Perceptron - accuracy: {best_value_mlp}\")\n",
        "\n",
        "# Optimización de K\n",
        "\n",
        "print('\\nK optimization')\n",
        "plt.scatter(*zip(*[i for i in vecinos if vecinos.index(i) % 2 == 0]))\n",
        "plt.axis((0, 100, 0.5, 1))\n",
        "plt.xlabel('Valor de k', fontsize=15)\n",
        "plt.ylabel('Accuracy', fontsize=15)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "k7G3frP5TPV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con era de esperar, los resultados han empeorado ya que las distancias se han elegido sin ningún criterio específico. Con esta prueba hemos logrado comprobar que con estas distancias la identificación en tiempo real es viable por lo que nuestra tarea consistirá en obtener las distancias más relevantes."
      ],
      "metadata": {
        "id": "GrJv68-BTRZz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PRUEBA 3: UTILIZANDO DISTANCIAS CON MAYOR CORRELACIÓN"
      ],
      "metadata": {
        "id": "-CoVRlq2Tz5K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta prueba, utilizaremos como criterio se elección de distancias la correlación con la clase. Para ello, veremos la distribución de correlaciones de las 2278 distancias y aplicaremos un umbral mínimo que se deba cumplir para que una distancia sea relevante."
      ],
      "metadata": {
        "id": "wq4MHcT2T7st"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zeenrr1oYB9T"
      },
      "outputs": [],
      "source": [
        "# Calcular correlación\n",
        "train_df_num = landmarks_train_df.copy()\n",
        "mapeo = {'ALEX': 0, 'ENDIKA': 1}\n",
        "train_df_num['Etiqueta'] = landmarks_train_df['Etiqueta'].map(mapeo)\n",
        "\n",
        "correlacion = train_df_num.corr()['Etiqueta']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizar la distribución de las distancias según su correlación con la clase\n",
        "\n",
        "# Font\n",
        "plt.rcParams['font.family'] = 'Serif'\n",
        "\n",
        "# Ajustar ancho y alto del gráfico\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "# Número de barras del histograma, colores y título\n",
        "plt.hist(correlacion, bins=120, edgecolor='#555555', alpha=0.95, color='#ffce93')\n",
        "plt.title('Distribución de los atributos por correlación', fontsize=16)\n",
        "# Eje X\n",
        "plt.xlabel('Correlación', fontsize=12)\n",
        "plt.xticks(np.linspace(-1, 1, num=11), fontsize=10)\n",
        "# Eje Y\n",
        "plt.yticks(fontsize=10)\n",
        "plt.ylabel('Número de atributos', fontsize=12)\n",
        "plt.grid(True)\n",
        "\n",
        "# Agregar una línea vertical en el 0\n",
        "plt.axvline(0, color='red', linestyle='dashed', linewidth=1, label=f'')\n",
        "# plt.legend()\n",
        "\n",
        "# Mostrar el gráfico\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "OwfVgFvUT7Uk",
        "outputId": "d3a12fee-bdcb-4997-9913-daca349b7744"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-ede595fb5b07>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Para printear la correlación\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdatos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Correlacion'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Font\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como podemos observar que la gran mayoría de las distancias tiene una correlación entre 0 y 0.5 con la clase. Nuestra tarea consiste en descartar aquellas que tengas valores mínimos ya que no aportan ningún tipo de información relevante al modelo y, además, pueden introducir ruido."
      ],
      "metadata": {
        "id": "QFGeklvWVN-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener columnas con correlación que superen el threshold\n",
        "CORRELATION_THRESHOLD = 0.6\n",
        "\n",
        "corr_df = pd.DataFrame(data=correlacion)\n",
        "corr_df.reset_index(inplace=True)\n",
        "corr_df = corr_df.rename({'index': 'Puntos', 'Etiqueta': 'Correlacion'}, axis=1)\n",
        "\n",
        "corr_df\n",
        "best_headers = []\n",
        "for i in range(0,len(corr_df)):\n",
        "    if abs(corr_df['Correlacion'][i]) > CORRELATION_THRESHOLD and corr_df['Puntos'][i]!='Etiqueta':\n",
        "        best_headers.append(f\"{corr_df['Puntos'][i]}\")\n",
        "\n",
        "print(f\"New headers: {best_headers}\")\n",
        "print(f\"Num headers: {len(best_headers)}\")\n",
        "\n",
        "# Cargar nuevo train y test\n",
        "\n",
        "#TODO COGER SOLO LAS BEST COLUMNS\n",
        "X_train_prueba3 = landmarks_train_df.drop(['Etiqueta'], axis=1)\n",
        "y_train_prueba3 = landmarks_train_df['Etiqueta']\n",
        "\n",
        "X_test_prueba3 = landmarks_train_df.drop(['Etiqueta'], axis=1)\n",
        "y_test_prueba3 = landmarks_train_df['Etiqueta']"
      ],
      "metadata": {
        "id": "0-KUjjyHVNKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En la siguiente imagen podemos observar las únicas distancias que superan el umbral:"
      ],
      "metadata": {
        "id": "u1Fc4zkccUNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imagen = cv2.imread('data/keanu_grande.jpg')\n",
        "\n",
        "for pts in best_headers:\n",
        "    i, j = pts.split('TO')\n",
        "\n",
        "\n",
        "    start_point = (shape[int(i)][0], shape[int(i)][1])\n",
        "\n",
        "    end_point = (int(shape[int(j)][0]),int(shape[int(j)][1]))\n",
        "\n",
        "    color = (0, 255, 0)\n",
        "    keanu_importantes = cv2.line(keanu_importantes, start_point, end_point, color, 1)\n",
        "\n",
        "# cv2.imwrite('keanu_importantes.jpg', keanu_importantes)\n",
        "cv2_imshow(imagen)"
      ],
      "metadata": {
        "id": "agPV0B_PcjR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###### Regresión Logística ######\n",
        "\n",
        "rl_model = LogisticRegression(max_iter=10000)\n",
        "rl_model.fit(X_train_prueba3, y_train_prueba3)\n",
        "best_value_lr = rl_model.score(X_test_prueba3, y_test_prueba3)\n",
        "\n",
        "\n",
        "#### Multi-layer Perceptron #####\n",
        "\n",
        "mlp_model = MLPClassifier(\n",
        "    hidden_layer_sizes=[20, 40],\n",
        "    activation='relu',\n",
        "    early_stopping=True,\n",
        "    +\n",
        "    random_state=13,\n",
        "    max_iter=10000,\n",
        "    solver='adam',\n",
        "    verbose=False\n",
        ")\n",
        "mlp_model.fit(X_train_prueba3, y_train_prueba3)\n",
        "best_value_mlp = mlp_model.score(X_test_prueba3, y_test_prueba3)\n",
        "\n",
        "\n",
        "###### K Nearst Neighbors #######\n",
        "\n",
        "vecinos =  []\n",
        "for k in range(1, 101):\n",
        "    model = KNeighborsClassifier(k)\n",
        "    model.fit(X_train_prueba3, y_train_prueba3)\n",
        "    vecinos.append((k, model.score(X_test_prueba3, y_test_prueba3)))\n",
        "\n",
        "# Accuracy máximo obtenido\n",
        "best_value_knn = max(vecinos, key=lambda x:x[1])[1]\n",
        "\n",
        "########## Resultados ###########\n",
        "\n",
        "print(f\"K Nearst Neighbors - accuracy: {best_value_knn}\")\n",
        "print(f\"Logistic Regression - accuracy: {best_value_lr}\")\n",
        "print(f\"Multi-layer Perceptron - accuracy: {best_value_mlp}\")\n",
        "\n",
        "# Optimización de K\n",
        "\n",
        "print('\\nK optimization')\n",
        "plt.scatter(*zip(*[i for i in vecinos if vecinos.index(i) % 2 == 0]))\n",
        "plt.axis((0, 100, 0.5, 1))\n",
        "plt.xlabel('Valor de k', fontsize=15)\n",
        "plt.ylabel('Accuracy', fontsize=15)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3_Sr6vXFWPSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observamos que utilizando las distancias con mayor correlación se obtienen mejores métricas y además garantizamos que sea viable realizar la identificación en tiempo real."
      ],
      "metadata": {
        "id": "4LKVq3a-Xmp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CONCLUSIONES\n",
        "En estas pruebas se han utilizado 2 caras distintas para la optimización, pero al hacer pruebas con otros rostros veíamos que los resultados no eran igual de bueno. Esto se debe a que a medida que se añaden distintos rostros, la correlación de cada distancia puede variar.\n",
        "\n",
        "Ejemplo: Comparando a 2 personas que tienen una nariz del mismo tamaño, la correlación de las medidas internas de la nariz será 0, ya que no aporta ninguna información para distinguir estos rostro. Al introducir una nueva persona en el sistema con una nariz considerablemente más grande o más pequeña, hace que estas distancias sean más relevantes para la distinción, por lo que su correlación aumenta.\n",
        "\n",
        "Para asegurarnos siempre de que se utilizan las distancias más relevantes utilizamos columnas dinámicas, es decir, durante el periodo de entrenamiento, se calcula automáticamente qué distancias superan el threshold y únicamente estas se utilizan para el entrenamiento. De esta forma, obtendremos buenas métricas independientemente de tipo o número de rostros.\n",
        "\n",
        "El código del sistema desarrollado se encuentra en GitHub:\n",
        "https://github.com/EndikaEiros/Detecion_Facial"
      ],
      "metadata": {
        "id": "33YFTzS5X7FO"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}